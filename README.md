# B2B Data Pipeline â€“ IndiaMART  
End-to-End Data Engineering & Exploratory Analysis (Slooze Take-Home Challenge)

This repository contains an end-to-end B2B data engineering pipeline built as part of the **Slooze take-home challenge**:

**IndiaMART Web Scraping â†’ ETL â†’ Exploratory Data Analysis (10 Charts) â†’ Local Django Dashboard**

The project demonstrates practical data collection, cleaning, analysis, and visualization, with an emphasis on robustness, reproducibility, and business-oriented insights.

---

## ğŸš€ Overview

### Part A â€” Data Collection (IndiaMART)
- Scrapes product listings across multiple keywords/categories
- Implements retry with backoff and polite rate-limiting to reduce blocking
- Produces structured outputs in CSV (with optional SQLite artifacts)
- Designed to be configurable and restartable (checkpoint support)

### Part B â€” Exploratory Data Analysis (EDA)
- Cleans and standardizes scraped data (price parsing, bucketing, regions)
- Generates **exactly 10 professional charts** saved to `/plots`
- Produces tabular reports in `/reports` and qualitative insights in `EDA_INSIGHTS.md`

### Dashboard (Bonus)
- Local Django dashboard to explore KPIs, charts, and a data table
- Uses `clean_data.csv` generated by the ETL step as its primary data source
- Intended as a lightweight visualization layer (not production hosting)

---

## ğŸ“ Project Structure

.
â”œâ”€â”€ scraper.py # IndiaMART data collector
â”œâ”€â”€ etl.py # Cleaning + transformation + schema enforcement
â”œâ”€â”€ analysis.py # EDA + generation of exactly 10 charts
â”œâ”€â”€ main.py # End-to-end runner (ETL + EDA)
â”œâ”€â”€ clean_data.csv # Cleaned dataset
â”œâ”€â”€ plots/ # Generated chart images (10 total)
â”œâ”€â”€ reports/ # Summary CSV reports
â”œâ”€â”€ EDA_INSIGHTS.md # Qualitative insights
â”œâ”€â”€ dashboard/ # Django app (local dashboard)
â””â”€â”€ requirements.txt


---

## âš™ï¸ Setup

```bash
python -m venv venv

# Windows
venv\Scripts\activate

# macOS / Linux
# source venv/bin/activate

pip install -r requirements.txt
â–¶ï¸ Run
Run full pipeline (ETL + EDA)
python main.py
Run EDA only (regenerates charts + reports)
python analysis.py
Run Django dashboard (local)
cd dashboard
python manage.py runserver
Then open:

http://127.0.0.1:8000/

ğŸ“Š Outputs
Charts (Exactly 10)
Saved in /plots:

KPI Cards

Line Chart

Bar Chart

Donut Chart

Histogram (Price Distribution)

Map Approximation (City Index)

Combo Chart (Bar + Line)

Treemap

Waterfall Chart

Scatter Plot

Reports
Saved in /reports:

Dataset summary statistics

Missingness & data quality checks

Outlier listings

Top product keyword/token frequencies

ğŸ§¾ Data Quality Summary
A brief summary (full details available in EDA_INSIGHTS.md and /reports):

~27% of listings have missing price (many sellers do not publish prices publicly)

~27% of listings have missing ratings

Duplicate suppliers/products are handled via ID + name normalization

High price outliers are flagged (not dropped) to preserve industrial/bulk listings

Price values are parsed into numeric form and bucketed (Low / Mid / High / Unknown)

Location fields are standardized into city, state, and supplier region

Some records contain incomplete metadata due to marketplace UI constraints

Limitations
Certain sellers intentionally hide prices or ratings

Results may reflect sampling bias from chosen keywords and marketplace personalization

Location data quality depends on seller-provided information

ğŸ§  Analytical Hypotheses
Exploratory observations based on this dataset:

The South region appears to dominate listings, which may indicate sampling bias from selected keywords or IndiaMART search personalization.

A large â€œUnknownâ€ price bucket suggests that price visibility may correlate with seller tier or product category.

Extreme price outliers likely represent bulk or industrial orders; downstream dashboards may benefit from optional outlier capping for visualization clarity.

ğŸ—„ï¸ Database Artifacts
This repository currently includes:

products.db

dashboard/db.sqlite3

These SQLite files are generated artifacts and are included only for quick local demo and inspection.
In a production workflow, these would typically be excluded and regenerated from the pipeline.

ğŸ›¡ï¸ Git Ignore Recommendations
If you prefer not to version generated artifacts locally, consider adding the following to .gitignore:

*.db
__pycache__/
*.pyc
.env
venv/
(If keeping databases for demo purposes, do not ignore *.db.)

ğŸ“¸ Dashboard Preview
You can embed screenshots here, for example:

## Dashboard Preview
![Dashboard](plots/01_kpi_cards.png)
Optionally place UI screenshots in a /screenshots folder and reference them.

ğŸ“¬ Contact
Kathir Ranjanaa S
Email: kathirranjanaas@gmail.com
Phone: +91 9345512491
GitHub: https://github.com/Kathirranjanaa
LinkedIn: https://www.linkedin.com/in/kathir-ranjanaa-s/

Slooze submission: careers@slooze.xyz


---

# âœ… Step 2 â€” Update `.gitignore`

Open `.gitignore` and append this at the bottom:

*.db
pycache/
*.pyc
.env
venv/


(If you want to keep DBs tracked, remove `*.db`.)

---

# âœ… Step 3 â€” Commit README + .gitignore

Run:

```powershell
git add README.md .gitignore
git commit -m "Improve README and gitignore for professional submission"
git push
